import torch
import torch.nn as nn
import torch.nn.functional as F
from .unet import ClassicUNet
from segment_anything import sam_model_registry


class ProjectorBlock(nn.Module):
    def __init__(self, in_channels=256, out_channels=512):
        super().__init__()
        self.block = nn.Sequential(
            nn.Conv2d(in_channels, out_channels, 3, padding=1),
            nn.GroupNorm(8, out_channels),
            nn.ReLU(inplace=True),
            nn.Conv2d(out_channels, out_channels, 3, padding=1),
            nn.GroupNorm(8, out_channels),
            nn.ReLU(inplace=True)
        )

    def forward(self, x):
        return self.block(x)


class SAM2UNet(nn.Module):
    def __init__(self, checkpoint: str, in_channels: int = 1, out_channels: int = 1, img_size: int = 512):
        """
        SAM2-UNet: SAM encoder (ViT-H) + ê°•í™”ëœ projector + ClassicUNet decoder
        AMP ì—†ì´ êµ¬ì„±. ì¼ë¶€ encoderë§Œ fine-tune

        Args:
            checkpoint (str): SAM ëª¨ë¸ì˜ checkpoint ê²½ë¡œ (.pth)
            in_channels (int): ì…ë ¥ ì±„ë„ ìˆ˜ (CT ì´ë¯¸ì§€: 1)
            out_channels (int): ì¶œë ¥ ì±„ë„ ìˆ˜ (ë³´í†µ 1)
            img_size (int): SAM encoder ì…ë ¥ í¬ê¸° (ê¸°ë³¸ 640)
        """
        super().__init__()

        # 1. SAM encoder ë¡œë“œ (ViT-H)
        self.sam = sam_model_registry["vit_b"](checkpoint=checkpoint)

        # 2. encoder ì¼ë¶€ fine-tuning í—ˆìš© (blocks.6~11 + norm)
        for p in self.sam.image_encoder.parameters():
            p.requires_grad = False
        for name, p in self.sam.image_encoder.named_parameters():
            if any(k in name for k in ["blocks.4", "blocks.5", "blocks.6", "blocks.7", "blocks.8", "blocks.9", "blocks.10", "blocks.11", "norm"]):
                p.requires_grad = True

        # 3. projector
        self.projector = ProjectorBlock(in_channels=256, out_channels=256)

        # 4. decoder
        self.decoder = ClassicUNet(in_channels=256, out_channels=out_channels)

        # 5. Decoder ë§ˆì§€ë§‰ ì¶œë ¥ì¸µì˜ bias ì´ˆê¸°ê°’ ì„¤ì • ë° í•™ìŠµ ê°€ëŠ¥í•˜ë„ë¡ ìˆ˜ì •
        self.final_conv_ref = None
        for m in self.decoder.modules():
            if isinstance(m, nn.Conv2d) and m.out_channels == out_channels:
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0.0)
                    m.bias.requires_grad = True
                    self.final_conv_ref = m

    def forward(self, x):
        if x.shape[1] == 1:
            x = x.repeat(1, 3, 1, 1)

        # ğŸ”µ A. Encoder ì¶œë ¥ í™•ì¸
        feats = self.sam.image_encoder(x)
        # print(f"\n[ENCODER OUTPUT]")
        # print(f"Shape: {feats.shape}")
        # print(f"Mean: {feats.mean().item():.6f}, Std: {feats.std().item():.6f}, Min: {feats.min().item():.6f}, Max: {feats.max().item():.6f}")

        # ğŸŸ¢ B. Projector ì¶œë ¥ í™•ì¸
        proj = self.projector(feats)
        # print(f"[PROJECTOR OUTPUT]")
        # print(f"Shape: {proj.shape}")
        # print(f"Mean: {proj.mean().item():.6f}, Std: {proj.std().item():.6f}, Min: {proj.min().item():.6f}, Max: {proj.max().item():.6f}")

        # ğŸŸ£ C. Decoder ì¶œë ¥ í™•ì¸
        out = self.decoder(proj)
        out = F.interpolate(out, size=x.shape[2:], mode='bilinear', align_corners=False)

        return out
