model:
  name: sam2unet
  img_size: 512
  patch_size: 32  # 기존 16에서 32로 증가
  checkpoint: weights/sam_vit_b_01ec64.pth  # 메모리 절감을 위한 ViT-B 사용
  grad_checkpointing: true
  freeze_layers: 0  # 완전 fine-tune (일부 freeze 원할 경우 숫자 조정)

experiment:
  name: sam2unet_hu_dice_focal_epoch50_pretrained
  seed: 42

data:
  root_dir: "C:/Users/Hyojun Park/Paper/ct-segmentation/content/data"
  threshold: 0.3

train:
  batch_size: 4
  epochs: 50
  lr: 0.0001
  loss: dice_focal
  save_dir: outputs/sam2unet_dice_focal_epoch50_pretrained
  num_workers: 4
  patience: 10
  use_amp: true

eval:
  visualize: true
